#!/usr/bin/env python3
"""
é‡æ–°ç”Ÿæˆå·²æœ‰è®­ç»ƒçš„å›¾è¡¨
Regenerate plots from existing training runs
"""

import os
import glob
import numpy as np
import matplotlib.pyplot as plt
from tensorboard.backend.event_processing.event_accumulator import EventAccumulator
from scipy.ndimage import uniform_filter1d

def plot_training_curves(run_dir, scenario_name, script_dir):
    """ä»TensorBoardæ—¥å¿—ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
    try:
        # åˆ›å»ºè¾“å‡ºç›®å½•
        plot_dir = script_dir
        os.makedirs(plot_dir, exist_ok=True)
        
        # ä½¿ç”¨EventAccumulatorè¯»å–TensorBoardæ—¥å¿—
        event_acc = EventAccumulator(run_dir)
        event_acc.Reload()
        
        print(f"\nğŸ“Š Reading TensorBoard logs from: {run_dir}")
        
        # è·å–æ‰€æœ‰æ ‡ç­¾
        tags = event_acc.Tags()
        print(f"Available tags: {tags}")
        
        # è·å–æ ‡é‡æ•°æ®
        if 'scalars' not in tags or not tags['scalars']:
            print(f"âš ï¸  Warning: No scalar data found in {run_dir}")
            return
            
        scalars = tags['scalars']
        print(f"Scalar keys found: {scalars}")
        
        # æå–æ‰€æœ‰æ•°æ®
        data_dict = {}
        for scalar_name in scalars:
            try:
                events = event_acc.Scalars(scalar_name)
                if events:
                    steps = np.array([e.step for e in events])
                    values = np.array([e.value for e in events])
                    data_dict[scalar_name] = (steps, values)
                    print(f"  âœ“ {scalar_name}: {len(events)} data points")
            except Exception as e:
                print(f"  âœ— Failed to read {scalar_name}: {e}")
        
        if not data_dict:
            print(f"âš ï¸  Warning: No scalar data could be extracted from {run_dir}")
            return
        
        # åˆ›å»ºå­å›¾
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        fig.suptitle(f'Training Progress - {scenario_name.upper()}', fontsize=16, fontweight='bold')
        
        plot_count = 0
        
        # 1. ç­–ç•¥æŸå¤± (Policy Loss)
        policy_loss_keys = [k for k in data_dict.keys() if 'policy_loss' in k.lower()]
        if policy_loss_keys:
            key = policy_loss_keys[0]
            steps, values = data_dict[key]
            if len(steps) > 0:
                axes[0, 0].plot(steps, values, linewidth=2, color='#FF6B6B')
                axes[0, 0].set_title('Policy Loss', fontweight='bold')
                axes[0, 0].set_xlabel('Training Steps')
                axes[0, 0].set_ylabel('Loss')
                axes[0, 0].grid(True, alpha=0.3)
                plot_count += 1
                print(f"  ğŸ“ˆ Plotted: Policy Loss")
        else:
            axes[0, 0].text(0.5, 0.5, 'No Policy Loss Data', ha='center', va='center', transform=axes[0, 0].transAxes)
        
        # 2. ä»·å€¼å‡½æ•°æŸå¤± (Value Loss)
        value_loss_keys = [k for k in data_dict.keys() if 'value_loss' in k.lower()]
        if value_loss_keys:
            key = value_loss_keys[0]
            steps, values = data_dict[key]
            if len(steps) > 0:
                axes[0, 1].plot(steps, values, linewidth=2, color='#4ECDC4')
                axes[0, 1].set_title('Value Loss', fontweight='bold')
                axes[0, 1].set_xlabel('Training Steps')
                axes[0, 1].set_ylabel('Loss')
                axes[0, 1].grid(True, alpha=0.3)
                plot_count += 1
                print(f"  ğŸ“ˆ Plotted: Value Loss")
        else:
            axes[0, 1].text(0.5, 0.5, 'No Value Loss Data', ha='center', va='center', transform=axes[0, 1].transAxes)
        
        # 3. æ€»æŸå¤± (Entropy Loss or Clip Fraction)
        entropy_keys = [k for k in data_dict.keys() if 'entropy_loss' in k.lower()]
        clip_keys = [k for k in data_dict.keys() if 'clip_fraction' in k.lower()]
        
        if entropy_keys:
            key = entropy_keys[0]
            steps, values = data_dict[key]
            if len(steps) > 0:
                axes[1, 0].plot(steps, values, linewidth=2, color='#95E1D3')
                axes[1, 0].set_title('Entropy Loss', fontweight='bold')
                axes[1, 0].set_xlabel('Training Steps')
                axes[1, 0].set_ylabel('Loss')
                axes[1, 0].grid(True, alpha=0.3)
                plot_count += 1
                print(f"  ğŸ“ˆ Plotted: Entropy Loss")
        elif clip_keys:
            key = clip_keys[0]
            steps, values = data_dict[key]
            if len(steps) > 0:
                axes[1, 0].plot(steps, values, linewidth=2, color='#95E1D3')
                axes[1, 0].set_title('Clip Fraction', fontweight='bold')
                axes[1, 0].set_xlabel('Training Steps')
                axes[1, 0].set_ylabel('Fraction')
                axes[1, 0].grid(True, alpha=0.3)
                plot_count += 1
                print(f"  ğŸ“ˆ Plotted: Clip Fraction")
        else:
            axes[1, 0].text(0.5, 0.5, 'No Loss Data', ha='center', va='center', transform=axes[1, 0].transAxes)
        
        # 4. å¹³å‡å¥–åŠ± (Mean Episode Reward)
        reward_keys = [k for k in data_dict.keys() if 'ep_rew_mean' in k.lower()]
        if reward_keys:
            key = reward_keys[0]
            steps, values = data_dict[key]
            if len(steps) > 0:
                axes[1, 1].plot(steps, values, linewidth=2, color='#F7DC6F')
                axes[1, 1].fill_between(steps, values, alpha=0.3, color='#F7DC6F')
                axes[1, 1].set_title('Mean Episode Reward', fontweight='bold')
                axes[1, 1].set_xlabel('Training Steps')
                axes[1, 1].set_ylabel('Reward')
                axes[1, 1].grid(True, alpha=0.3)
                plot_count += 1
                print(f"  ğŸ“ˆ Plotted: Mean Episode Reward")
        else:
            axes[1, 1].text(0.5, 0.5, 'No Reward Data', ha='center', va='center', transform=axes[1, 1].transAxes)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨åˆ°å½“å‰ç›®å½•
        plot_path = os.path.join(plot_dir, f'training_curves_{scenario_name}_run_{os.path.basename(run_dir)}.png')
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        print(f"âœ… Training curves saved to: {plot_path}")
        
        plt.close()
        
        # ç»˜åˆ¶è¯¦ç»†çš„å¥–åŠ±æ›²çº¿
        reward_keys = [k for k in data_dict.keys() if 'ep_rew_mean' in k.lower()]
        if reward_keys:
            fig, ax = plt.subplots(figsize=(12, 6))
            key = reward_keys[0]
            steps, values = data_dict[key]
            
            if len(steps) > 0:
                # å¹³æ»‘æ›²çº¿
                if len(values) > 20:
                    smoothed = uniform_filter1d(values, size=20)
                elif len(values) > 5:
                    smoothed = uniform_filter1d(values, size=5)
                else:
                    smoothed = values
                
                ax.plot(steps, values, alpha=0.3, color='#4ECDC4', label='Raw Reward')
                ax.plot(steps, smoothed, linewidth=2.5, color='#FF6B6B', label='Smoothed Reward')
                ax.fill_between(steps, values, alpha=0.1, color='#4ECDC4')
                ax.set_title(f'Episode Reward Over Training - {scenario_name.upper()}', fontsize=14, fontweight='bold')
                ax.set_xlabel('Training Steps', fontsize=12)
                ax.set_ylabel('Mean Episode Reward', fontsize=12)
                ax.legend(fontsize=11)
                ax.grid(True, alpha=0.3)
                
                plt.tight_layout()
                reward_plot_path = os.path.join(plot_dir, f'reward_curve_{scenario_name}_run_{os.path.basename(run_dir)}.png')
                plt.savefig(reward_plot_path, dpi=300, bbox_inches='tight')
                print(f"âœ… Reward curve saved to: {reward_plot_path}")
                plt.close()
        
        print(f"ğŸ“Š Total plots generated: {plot_count + 1 if reward_keys else plot_count}")
        
    except Exception as e:
        print(f"âŒ Error plotting training curves: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # è·å–å½“å‰è„šæœ¬çš„ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    
    # å®šä¹‰åœºæ™¯æ˜ å°„
    scenarios = {
        'highway_merge': 'highway_merge',
        'parking': 'parking',
        'roundabout': 'roundabout',
    }
    
    # æ‰«ææ‰€æœ‰å·²æœ‰çš„è®­ç»ƒç›®å½•
    print("ğŸ” Scanning for existing training runs...\n")
    
    base_dir = os.path.join(script_dir, 'highway_ppo')
    
    for scenario_key, scenario_name in scenarios.items():
        scenario_dir = os.path.join(base_dir, scenario_key)
        
        if not os.path.exists(scenario_dir):
            print(f"âš ï¸  Directory not found: {scenario_dir}")
            continue
        
        # æŸ¥æ‰¾æ‰€æœ‰runç›®å½•
        run_dirs = sorted(glob.glob(os.path.join(scenario_dir, 'run_*', 'PPO_1')))
        
        if not run_dirs:
            print(f"âš ï¸  No training runs found in: {scenario_dir}")
            continue
        
        print(f"ğŸ“ Found {scenario_key}: {len(run_dirs)} run(s)")
        
        for run_dir in run_dirs:
            run_name = os.path.basename(os.path.dirname(run_dir))
            print(f"\n{'=' * 60}")
            print(f"Processing: {scenario_name} / {run_name}")
            print(f"{'=' * 60}")
            
            plot_training_curves(run_dir, scenario_name, script_dir)
    
    print(f"\n{'=' * 60}")
    print("âœ… All plots regenerated successfully!")
    print(f"{'=' * 60}")
